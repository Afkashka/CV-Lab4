{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biSzZfDJ2uZ4",
        "outputId": "785ca4a7-4fc4-4e81-ab3f-f5e4f1e9b3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VeyZ3RCMt39"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "#from torch.nn import functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "#from torch import optim\n",
        "import os\n",
        "import csv\n",
        "#from PIL import Image\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchmetrics.functional.classification import multiclass_precision\n",
        "from torchmetrics.functional.classification import multiclass_recall\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlvv8VBFvZAx"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = (0.4800, 0.4609, 0.4225), std = (0.2588, 0.2551, 0.2769))\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e8M_cvIBHvI"
      },
      "outputs": [],
      "source": [
        "testset = ImageFolder(root=\"/content/drive/MyDrive/data_sun397_test\",transform=transform)\n",
        "trainset = ImageFolder(root=\"/content/drive/MyDrive/data_sun397\",transform=transform)\n",
        "\n",
        "#train_size = int(0.6 * len(dataset))\n",
        "#test_size = int((len(dataset) - train_size) / 2)\n",
        "#valid_size = int((len(dataset) - train_size) / 2)\n",
        "\n",
        "test_size = int(len(testset) *0.6)\n",
        "valid_size = int(len(testset) - test_size)\n",
        "\n",
        "#train, test, valid = torch.utils.data.random_split(dataset, [train_size, test_size, valid_size])\n",
        "test, valid = torch.utils.data.random_split(testset, [test_size, valid_size])\n",
        "\n",
        "train = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle = True, num_workers = 32 )\n",
        "test = torch.utils.data.DataLoader(test, batch_size=64, shuffle = True, num_workers = 32)\n",
        "valid = torch.utils.data.DataLoader(valid, batch_size=64, shuffle = True, num_workers = 32 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_mean_and_sd(loader):\n",
        "    \n",
        "    cnt = 0\n",
        "    fst_moment = torch.empty(3)\n",
        "    snd_moment = torch.empty(3)\n",
        "\n",
        "    for images, _ in loader:\n",
        "        b, c, h, w = images.shape\n",
        "        nb_pixels = b * h * w\n",
        "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
        "        sum_of_square = torch.sum(images ** 2,\n",
        "                                  dim=[0, 2, 3])\n",
        "        fst_moment = (cnt * fst_moment + sum_) / (\n",
        "                      cnt + nb_pixels)\n",
        "        snd_moment = (cnt * snd_moment + sum_of_square) / (\n",
        "                            cnt + nb_pixels)\n",
        "        cnt += nb_pixels\n",
        "\n",
        "    mean, std = fst_moment, torch.sqrt(\n",
        "      snd_moment - fst_moment ** 2)        \n",
        "    return mean,std\n"
      ],
      "metadata": {
        "id": "p-_ygnuZWaNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, std = batch_mean_and_sd(train)\n",
        "print(\"mean and std: \\n\", mean, std)"
      ],
      "metadata": {
        "id": "1W9Tsh2cIoul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67Yqf7fhTN2e"
      },
      "outputs": [],
      "source": [
        "import torchvision.models\n",
        "model = torchvision.models.resnet18(weights = None)\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.linear = torch.nn.Linear(512, 397)\n",
        "    self.activation = torch.nn.Softmax(1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.activation(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "model.fc = Classifier()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf0POmTl5BE3"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('/content/resnet_sun397 tot.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT0LzLWONcA6",
        "outputId": "c3561ef6-e8dc-46c7-fe53-ffecbc6e4454"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f87b6e35c70>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "torch.manual_seed(1234) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHiBwIBINW5h"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "model = model.to(device)\n",
        "#model.cuda(0)\n",
        "loss_fn = nn.CrossEntropyLoss() #Select loss_function\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=1e-4) #Selec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTrhQGmEqcjs"
      },
      "outputs": [],
      "source": [
        "def get_metrics(model,loader):\n",
        "    labels = []\n",
        "    pred_labels = []\n",
        "    labels = torch.cuda.FloatTensor(labels)\n",
        "    pred_labels  = torch.cuda.FloatTensor(pred_labels)\n",
        "\n",
        "    for img,label in loader:\n",
        "        img,label = img.to(device),label.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(img)       \n",
        "            pred = logits #.argmax(dim=1)\n",
        "\n",
        "        labels = torch.cat((labels,label))\n",
        "        pred_labels = torch.cat((pred_labels,pred))\n",
        "\n",
        "    return multiclass_precision(pred_labels, labels, 397), multiclass_recall(pred_labels, labels, 397)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 6)"
      ],
      "metadata": {
        "id": "W9QkLld-HXqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqxKNXcKPFfQ"
      },
      "outputs": [],
      "source": [
        "best_epoch, best_prec = 0, 0, 0\n",
        "valid_loss = 0\n",
        "loss_history = []\n",
        "prec_history = []\n",
        "recall_history = []\n",
        "for epoch in range(60):  \n",
        "    model.train()\n",
        "    for batch_num, (img, label) in enumerate(train):\n",
        "        img,label = img.to(device),label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(img)\n",
        "\n",
        "        loss = loss_fn(logits, label)\n",
        "        \n",
        "        if (batch_num + 1) % 50  == 0:\n",
        "            print('{}th batch of the {}th epoch, loss {}'.format(batch_num + 1, epoch + 1,\n",
        "                                                                                        loss.item()))\n",
        "            loss_history.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    prec, rec = get_metrics(model, valid)\n",
        "\n",
        "    prec_history.append(prec.item())\n",
        "    recall_history.append(rec.item())\n",
        "    \n",
        "    for img, label in valid:\n",
        "        if torch.cuda.is_available():\n",
        "            img,label = img.to(device),label.to(device)\n",
        "  \n",
        "        target = model(img)\n",
        "        valid_step_loss = loss_fn(target, label)\n",
        "        valid_loss += valid_step_loss.item() * img.size(0)\n",
        "\n",
        "\n",
        "    if prec > best_prec:\n",
        "         print('Precision: {}'.format(prec))\n",
        "         print('Recall: {}'.format(rec))\n",
        "\n",
        "         best_epoch = epoch\n",
        "         best_prec = prec\n",
        "         torch.save(model.state_dict(), 'resnet_sun397 ep ' + str(epoch+1)+'.txt')\n",
        "\n",
        "    print(f'Epoch {epoch}\\t \\\n",
        "            Validation Loss:{valid_loss/len(valid)}')\n",
        "    print('LR: ',(optimizer.param_groups[0]['lr']))\n",
        "    scheduler.step(valid_loss/len(valid))\n",
        "    valid_loss = 0\n",
        "\n",
        "print('best_prec:{},best_epoch:{}'.format(best_prec, best_epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaymujizb9pw",
        "outputId": "f2708110-4cc4-42c2-d442-d5259fd385a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor(0.3542, device='cuda:0'), tensor(0.3532, device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "print(get_metrics(model,test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXqnYr7p_aAn"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'resnet_sun397.txt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}